# -*- coding: utf-8 -*-
"""Курсовая.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jdeHTaZgIlPA_PT96sj6GtnTy_zAV71X

## *Сравнение методов обработки пропущенных данных на примере набора с реальными пропусками*.

## 1. Введение

В реальных данных, полученных из различных источников, почти всегда встречаются пропущенные значения ($missing values$). Причины их возникновения могут быть самыми разными: отказ респондентов отвечать на определенные вопросы, технические сбои при передаче или хранении данных, невозможность измерения некоторых параметров в конкретных условиях или даже человеческий фактор при ручном вводе информации.

Проблема пропущенных данных особенно актуальна в машинном обучении и статистическом анализе, поскольку большинство алгоритмов  не могут корректно работать с неполными наборами данных. Это вынуждает исследователей либо удалять строки с пропусками, либо заполнять их с помощью специальных методов. Однако неправильный выбор стратегии обработки пропусков может исказить исходное распределение данных, снизить качество модели или привести к ошибочным выводам.


---



### **Актуальность темы**

В условиях роста объемов данных и их разнообразия задача корректной обработки пропусков становится все более важной. Не существует единого метода, который позволяет идеально обрабатывать пропуски, поэтому сравнение различных техник на реальных данных представляет значительный практический интерес.


---


### **Цель работы**

Провести сравнительный анализ методов обработки пропущенных значений в наборе данных с реальными пропусками, оценить их эффективность и выявить наилучшие стратегии.


---

### **Задачи исследования**

1. Изучить основные виды пропущенных данных.

2. Рассмотреть методы восстановления пропусков.

3. Применить различные методы импутации к реальному набору данных с пропусками.

4. Оценить качество восстановления данных с помощью метрик.

5. Сформулировать рекомендации по выбору метода заполнения пропуков.


---



 ### **Объект и предмет исследования**

*Объект исследования* : наборы данных с реальными пропущенными значениями.

*Предмет исследования* : методы обработки пропусков и их влияние на качество данных.



---


### **Практическая значимость**

Результаты исследования помогут специалистам по анализу данных выбирать оптимальные стратегии обработки пропусков в зависимости от характера данных, что повысит точность моделей машинного обучения и достоверность статистических выводов.

## Импорты библиотек

Перед началом необходимо импортировать все необходимые для работы библиотеки
"""

# Основные библиотеки для работы с данными и вычислений
import pandas as pd  # Для работы с табличными данными
import numpy as np   # Для численных операций и работы с массивами
import matplotlib.pyplot as plt  # Для построения графиков и визуализации
import seaborn as sns
import time  # Для работы со временем
import kagglehub  # Для работы с моделями и датасетами с Kaggle
import os

# Импорт  моделей из scikit-learn
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import (
    BaggingRegressor,
    RandomForestRegressor,
    ExtraTreesRegressor,
    HistGradientBoostingRegressor)
from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor

# Методы для обработки пропущенных значений
from sklearn.impute import SimpleImputer
from sklearn.impute import KNNImputer
from sklearn.cluster import KMeans
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

# Методы предварительной обработки данных и оценки моделей
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import (
    mean_squared_error,
    mean_absolute_error,
    r2_score,
    mean_squared_log_error)

"""А так же напишем свои функции для вычисления дополнительных метрик, которых нет в sklearn."""

# Для расчета Mean Absolute Percentage Error (MAPE) напишем функцию

def mean_absolute_percentage_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# Для расчета Median Absolute Error (MedAE) напишем функцию

def median_absolute_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.median(np.abs(y_true - y_pred))

# Для расчета Max Error напишем функцию

def max_error(y_true, y_pred):
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.max(np.abs(y_true - y_pred))

"""##2. Типы пропусков

1. **Полностью случайные пропуски (MCAR)**. Эти пропуски возникают независимо от значений как самого измеряемого признака, так и других признаков. Например, потеря образца крови пациента, что делает невозможным получение некоторых данных.

2. **Частично случайные пропуски (MAR)**. В этом случае вероятность пропуска зависит от значений других признаков, но не от самих пропущенных значений. Например, если пациенту с определённым диагнозом противопоказаны определённые анализы, то отсутствие данных будет связано с диагнозом, но не с самими измеряемыми признаками.

3. **Неслучайные пропуски (NMAR)**. Эти пропуски происходят из-за значений самого признака. Например, если измеряемое значение выходит за пределы диапазона чувствительности прибора, то такой пропуск считается неслучайным.

Пропущенные значения в данных могут возникать по разным причинам, и их природа напрямую влияет на выбор метода обработки. В статистике и анализе данных выделяют три основных типа пропусков:

1. Полностью случайные пропуски ($MCAR$ – Missing Completely At Random)

2. Частично случайные пропуски ($MAR$ – Missing At Random)

3. Неслучайные пропуски ($NMAR$ – Not Missing At Random)

Рассмотрим каждый тип подробнее.

### 2.1. Полностью случайные пропуски (MCAR)

Пропуски являются $MCAR$, если вероятность их появления не зависит ни от каких наблюдаемых или ненаблюдаемых данных. То есть пропущенные значения образуются абсолютно случайно, и их отсутствие никак не связано с другими переменными.

#### Примеры:

*  Медицина: В клинических исследованиях пробирка с кровью случайно разбилась, и часть анализов не была проведена.

*  Социология: В опросе случайно пропущены несколько вопросов из-за технической ошибки в анкете.

*  Техника: Сбой датчика температуры в случайные моменты времени.

#### Как проверить, являются ли пропуски $MCAR$?

Один из способов — проверить, различаются ли распределения наблюдаемых данных в группах с пропусками и без них.
"""

data = pd.DataFrame({
    'Age': np.random.normal(30, 5, 100),
    'Income': np.random.normal(50000, 10000, 100)})

missing_mask = np.random.rand(100) < 0.2
data.loc[missing_mask, 'Income'] = np.nan

plt.figure(figsize=(10, 4))
sns.boxplot(x=data['Income'].isna(), y=data['Age'])
plt.title("Распределение Age в группах с пропусками и без (MCAR)")
plt.show()

plt.figure(figsize=(10, 4))
sns.histplot(data=data, x='Age', hue=data['Income'].isna(),element='step')
plt.title("Гистограмма распределения Age для групп с пропусками и без (MCAR)")
plt.show()

"""Распределение Age в группах с пропусками (True) и без (False) практически одинаковое, так как гистограммы распределения выглядят похожими. По ящикам с усами же мы видим, что медианы и квантили почти совпадают, что так же свидетельствует о том, что распределения наблюдаемых данных в группах с пропусками и без них почти не отличаются.

А это значит, что  пропуски в Income возникли случайно и не связаны с возрастом.

### 2.2.Частично случайные пропуски ($MAR$)

Пропуски являются $MAR$, если их вероятность зависит от других наблюдаемых переменных, но не зависит от самих пропущенных значений.

#### Примеры:

*  Медицина: Пациентам старше 60 лет реже назначают сложные анализы → пропуски в данных зависят от возраста, но не от самих результатов анализов.

*  Финансы: Люди с низким доходом реже указывают свой кредитный рейтинг → пропуски зависят от дохода, но не от реального кредитного рейтинга.

*  Маркетинг: Пользователи мобильных устройств реже заполняют длинные опросы → пропуски зависят от типа устройства, но не от ответов.

#### Как проверить, являются ли пропуски $MAR$?

Нужно проверить, есть ли статистическая связь между пропусками в одной переменной и значениями других переменных.
"""

# Добавляем MAR-пропуски в Income (чем старше человек, тем выше вероятность пропуска)
missing_mar_mask = (data['Age'] > 35) & (np.random.rand(100) < 0.5)
data.loc[missing_mar_mask, 'Income'] = np.nan

plt.figure(figsize=(10, 4))
sns.boxplot(x=data['Income'].isna(), y=data['Age'])
plt.title("Распределение Age в группах с пропусками и без (MAR)")
plt.show()

plt.figure(figsize=(10, 4))
sns.histplot(data=data, x='Age', hue=data['Income'].isna(),element='step')
plt.title("Гистограмма распределения Age для групп с пропусками и без (MAR)")
plt.show()

"""Как мы видим, здесь уже дела обстаят по другому. Распределния совсем не одинаковые для групп с пропусками и без. Так, в группе с пропусками в Income медиана и среднее значительно больше, чем в группе без пропусков.

А это значит, что это частично случайные пропуски ( $MAR$ ).

### 2.3. Неслучайные пропуски ($NMAR$)

Пропуски являются $NMAR$, если их вероятность зависит от самих пропущенных значений, даже если другие переменные учтены.

#### Примеры:

* Медицина: Пациенты с очень высоким уровнем стресса отказываются отвечать на вопросы о психическом здоровье → пропуски зависят от скрытого состояния.

* Экономика: Богатые люди отказываются указывать доход → пропуск зависит от самого дохода.

* Техника: Датчик не фиксирует значения выше 100°C → пропуски возникают при экстремальных значениях.

#### Как проверить, являются ли пропуски $NMAR$?

Прямая проверка сложна, так как пропущенные значения неизвестны.
Здесь в первую очерень стоит логически порассуждать. Ведь зачастую неслучайные пропуски логически обьяснимы и связаны с самим значеним (например, температура, которая просто по техническим причинам не может быть зафиксирована контретно этим измерительным устройством). То есть при $NMAR$ требуется проанализировать пропуски и попробовать устав=новить закономерность, которая служит признаком того, что это именно $NMAR$.

А если самому не удается обьснить причину  пропусков, то стоит обратиться к профессианалу в сфере, к которой относятся данные. Поскольку он осведомлен о всех тонкостях в данной области, и возможно он сможет вам подсказать какие-то факторы, которые могли являться причиной пропусков.

## 3. Методы обработки пропусков

###3.1. Удаление строк или столбцов с пропусками.

Если пропуски составляют небольшой процент от всего обьема данных и при удалении строк с ними данных остается достаточно для дальнейшей работы, то строки с выбросами можно просто удалить.

Если же есть столбец, в котором очень много пропусков, и который являеся не сильно важным для модели, то этот столбец с пропусками так же можно просто удалить.
"""

def remove_rows_with_missing_values(dataframe):
    """
    Удаляет строки с пропусками из DataFrame.

    :param dataframe: Исходный DataFrame
    :return: DataFrame без строк с пропусками
    """

    cleaned_dataframe = dataframe.dropna()
    return cleaned_dataframe

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df1 = pd.DataFrame(data)

df1 = remove_rows_with_missing_values(df1)
df1

"""###3.2. Замена константой

Иногда пропуски заменяют на специальное заранее определенное значение, например 0. Такой подход не уменьшает размеры выборки, но может вносить значения, которые сильно отличаются от исходных.

Данный метод лучше не применять для моделей, которые чувстивтельны к машстабу данных, потмоу что он искахает исходные данные.
"""

def fill_missing_values_with_constant(dataframe, constant=0):
    """
    Заменяет пропуски в DataFrame на заданную константу.

    :param dataframe: Исходный DataFrame
    :param constant: Константа для замены пропусков (0 по умолчанию)
    :return: DataFrame с замененными пропусками
    """
    filled_dataframe = dataframe.fillna(constant)
    return filled_dataframe

data = {'A': [1, 2, None, 4],'B': [5, None, None, 8],'C': [9, 10, 11, 12]}
df2 = pd.DataFrame(data)

df2 = fill_missing_values_with_constant(df2, 0)
df2

def fill_missing_values_with_constant(dataframe, constant=0):
    """
    Заменяет пропуски в DataFrame на заданную константу с использованием SimpleImputer.

    :param dataframe: Исходный DataFrame
    :param constant: Константа для замены пропусков (по умолчанию 0)
    :return: DataFrame с замененными пропусками
    """
    imputer = SimpleImputer(strategy='constant', fill_value=constant)
    imputed_data = imputer.fit_transform(dataframe)

    filled_dataframe = pd.DataFrame(imputed_data, columns=dataframe.columns)
    return filled_dataframe

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df2 = pd.DataFrame(data)

df2 = fill_missing_values_with_constant(df2, 0)
df2

"""###3.3. Замена средним или самым частым значением

Еще одним простым методом является замена на среднее значение или медиану для количественных признаков, и на моду (то есть самое часто встречающееся значение) для категориальных признаков.

Данный метод лушче предыдущих, поскольку учитывает имеющиеся данные, однако он может исказить распределение, тем самым ухудшив работу модели на других данных.
"""

#Функция замены пропусков на среднее значение по столбцу

def fill_missing_values_with_mean(dataframe):
    """
    Заменяет пропуски в DataFrame на среднее значение по столбцу.

    :param dataframe: Исходный DataFrame
    :return: DataFrame с замененными пропусками
    """

    column_means = dataframe.mean()

    filled_dataframe = dataframe.fillna(column_means)
    return filled_dataframe

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df = pd.DataFrame(data)

df3_1 = fill_missing_values_with_mean(df)
df3_1

def fill_missing_values_with_mean(dataframe):
    """
    Заменяет пропуски в DataFrame на среднее значение по столбцу с использованием SimpleImputer.

    :param dataframe: Исходный DataFrame
    :return: DataFrame с замененными пропусками
    """
    imputer = SimpleImputer(strategy='mean')
    imputed_data = imputer.fit_transform(dataframe)

    filled_dataframe = pd.DataFrame(imputed_data, columns=dataframe.columns)
    return filled_dataframe

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df3_1 = pd.DataFrame(data)

df3_1 = fill_missing_values_with_mean(df3_1)
df3_1

#Функция замены пропусков на медиану

def fill_missing_values_with_median(dataframe):
    """
    Заменяет пропуски в DataFrame на медиану по столбцу

    :param dataframe: Исходный DataFrame
    :return: DataFrame с замененными пропусками
    """

    column_medians = dataframe.median()


    filled_dataframe = dataframe.fillna(column_medians)
    return filled_dataframe

data = {'A': [1, 2, None, 4, 4], 'B': [5, None, None, 8, 8], 'C': [9, 10, 11, 12, 13]}
df = pd.DataFrame(data)

df3_2 = fill_missing_values_with_median(df)
df3_2

def fill_missing_values_with_median(dataframe):
    """
    Заменяет пропуски в DataFrame на медиану с использованием SimpleImputer.

    :param dataframe: Исходный DataFrame
    :return: DataFrame с замененными пропусками
    """
    imputer = SimpleImputer(strategy='median')
    imputed_data = imputer.fit_transform(dataframe)

    filled_dataframe = pd.DataFrame(imputed_data, columns=dataframe.columns)
    return filled_dataframe

data = {'A': [1, 2, None, 4, 4], 'B': [5, None, None, 8, 8], 'C': [9, 10, 11, 12, 13]}
df = pd.DataFrame(data)

df3_2 = fill_missing_values_with_median(df)
df3_2

#Функция замены пропусков на моду (если их несколько, выбираем первую)

def fill_missing_values_with_mode(dataframe):
    """
    Заменяет пропуски в DataFrame на моду.

    :param dataframe: Исходный DataFrame
    :return: DataFrame с замененными пропусками
    """
    column_modes = dataframe.mode().iloc[0]

    filled_dataframe = dataframe.fillna(column_modes)
    return filled_dataframe

data = {'A': [1, 2, None, 2], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df = pd.DataFrame(data)

df3_3 = fill_missing_values_with_mode(df)
df3_3

def fill_missing_values_with_median(dataframe):
    """
    Заменяет пропуски в DataFrame на моду с использованием SimpleImputer.

    :param dataframe: Исходный DataFrame
    :return: DataFrame с замененными пропусками
    """
    imputer = SimpleImputer(strategy='most_frequent')
    imputed_data = imputer.fit_transform(dataframe)

    filled_dataframe = pd.DataFrame(imputed_data, columns=dataframe.columns)
    return filled_dataframe

data = {'A': [1, 2, None, 2], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df3_3 = pd.DataFrame(data)

df3_3 = fill_missing_values_with_median(df3_3)
df3_3

"""###3.4. Заполнение случайным значением из распределения

Данный метод подразумевает заполнение пропусков случайными значениями из того же распеделения, что и исходные данные.

Но этот метод похдодит не для всех типов данных. Например, для категориальных признаков порой не возможно определить распределение. Да и если удается определить распределение, оно может быть очень сложным и многомерным. Тогда реализовать этот метод будет так же довольно сложной задачей.

В добавок к этому, если в данных много признаков, что на практике встречается почти всегда, то определять распределение для каждого из них очень проблематично.

Поэтому этот способ рассматривать не будем, так как на практике он практически не применим.

###3.5. Метод ближайших соседий (k - NN)

Данный метод основан на предположении на том, что близкие обьекты по заполненным значениям имеют и близкое к истиному пропущенное значение.

То есть находится k ближайших соседей по другим признакам и пропуск заполняется средним (или медианным) значением этих k соседей.
"""

def fill_missing_values_with_knn(dataframe, k=3):
    """
    Заменяет пропуски в DataFrame с использованием метода k-NN.

    :param dataframe: Исходный DataFrame
    :param k: Количество ближайших соседей (по умолчанию 3)
    :return: DataFrame с замененными пропусками
    """
    imputer = KNNImputer(n_neighbors=k)

    imputed_data = imputer.fit_transform(dataframe)

    filled_dataframe = pd.DataFrame(imputed_data, columns=dataframe.columns)
    return filled_dataframe

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df5 = pd.DataFrame(data)

df5 = fill_missing_values_with_knn(df5, k=2)
df5

"""### 3.6. Метод k-средних (k - Means)

Метод кластера так же предполагает, что близкие обьекты по одному призанку, так же будут близкими и по другим.

Только в данном случае исходный набор делится на k кластеров без учета пропусков (то есть по признакам без пропусков). А затем пропуски заменяются на средние значения в кластерей, в которых попол обьект с пропуском (значение центра кластера).
"""

def fill_missing_values_with_kmeans(dataframe, n_clusters=3):
    """
    Заполняет пропуски в DataFrame с использованием метода k-средних.

    :param dataframe: Исходный DataFrame с пропусками
    :param n_clusters: Количество кластеров для k-средних
    :return: DataFrame с заполненными пропусками
    """
    cleaned_dataframe = fill_missing_values_with_mean(dataframe)
    filled_dataframe = dataframe.copy()

    for column in dataframe.columns:
        missing_values = dataframe[column].isna()

        if missing_values.any():
            temp_data = dataframe.drop(column, axis=1).fillna(dataframe.mean())

            kmeans = KMeans(n_clusters=n_clusters, random_state=0)
            kmeans.fit(cleaned_dataframe.drop(column, axis=1))

            clusters = kmeans.predict(temp_data)

            for cluster_id in range(n_clusters):
                cluster_mask = (clusters == cluster_id)
                cluster_mean = cleaned_dataframe.loc[cleaned_dataframe.index.isin(dataframe.index[cluster_mask]), column].mean()
                filled_dataframe.loc[missing_values & cluster_mask, column] = cluster_mean

    return filled_dataframe

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df_filled = pd.DataFrame(data)

df_filled = fill_missing_values_with_kmeans(df_filled, n_clusters=2)
df_filled

"""###3.7. Использование моделей для предсказания пропущенных значений

Пропущенное значение можно заполнить, предсказав его с помощью алгоритмов машинного обучения.

То есть определятся коррелирующие призназнаки с тем, в котором находится пропуск, строится модель одним из алгоритмов МО, и наконец предсказывается пропуск на основе модели и тех признаков об обьекте, которые известны.
"""

def fill_missing_values_with_prediction(dataframe, model, metric=None, lower_corr=0.3):
    """
    Заменяет пропуски в DataFrame на предсказанные значения, используя указанную модель,
    и возвращает метрику качества предсказания (если задана).
    Отсекает столбцы с корреляцией меньше заданного порога.

    :param dataframe: Исходный DataFrame
    :param model: Модель машинного обучения (например, LinearRegression)
    :param metric: Функция для вычисления метрики качества (например, r2_score)
    :param lower_corr: Порог корреляции для отсечения столбцов
    :return: DataFrame с замененными пропусками и метрика качества (если задана)
    """
    filled_dataframe = dataframe.copy()
    imputer = SimpleImputer(strategy='mean')

    metrics_results = {}

    for column in filled_dataframe.columns:
        if filled_dataframe[column].isna().any():
            train_data = filled_dataframe.dropna(subset=[column])
            test_data = filled_dataframe[filled_dataframe[column].isna()]

            X_train = train_data.drop(columns=[column])
            y_train = train_data[column]

            correlations = X_train.corrwith(y_train).abs()
            selected_features = correlations[correlations > lower_corr].index
            X_train = X_train[selected_features]

            X_train_imputed = imputer.fit_transform(X_train)
            X_test_imputed = imputer.transform(test_data[selected_features])

            model.fit(X_train_imputed, y_train)

            predicted_values = model.predict(X_test_imputed)

            filled_dataframe.loc[filled_dataframe[column].isna(), column] = predicted_values

            if metric is not None:
                y_pred_train = model.predict(X_train_imputed)
                metric_value = metric(y_train, y_pred_train)
                metrics_results[column] = metric_value

    if metric is not None:
        return filled_dataframe, metrics_results
    else:
        return filled_dataframe

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df = pd.DataFrame(data)

df7, metrics = fill_missing_values_with_prediction(df, model = LinearRegression(), metric = r2_score, lower_corr = 0.2)
df7, metrics

"""Функция fill_missing_values_with_prediction получает на вход DataFrame. А вместе с ним ту модель, которую мы будем использовавать для предсказания пропущенного значения. А так же метрику, по которой будем оценивать качество предсказанного значения. И порогового значение корреляции. И благодаря этому модель учитывает только те столбцы, которые действительно коррелируют друг с другом.

На выходе же мы получаем DataFrame с замененными пропусками и метрику, по которой мы сможем понять, насколько точно были заменяны данные.

Однако в scikit-learn уже есть готовый метод MICE
"""

data = {'A': [1, 2, None, 4], 'B': [5, None, None, 8], 'C': [9, 10, 11, 12]}
df = pd.DataFrame(data)

mice_imputer = IterativeImputer(estimator=LinearRegression(), random_state=0)
data_imputed = mice_imputer.fit_transform(df)

df7_2 = pd.DataFrame(data_imputed, columns=df.columns)
df7_2

"""Алгоритм заполнения, который работает на основе алгоритма Random Forest.

### 3.8. Использование специальных моделей, работающих с None

Это не совсем метод обработки пропусков, сколько вариант того, что можно сделать, если обработать пропуски самому нет возможности.

В этому случае можно использовать модели, которые способны сами обрабатывать пропущенные значения.

К ним можно отнести: RandomForestClassifier, HistGradientBoosting, XGBoost, LightGBM.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import HistGradientBoostingClassifier
import xgboost as xgb

from sklearn.datasets import load_iris

data = load_iris()
X = data.data
y = data.target

X[0, 0] = np.nan

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = RandomForestClassifier()
model.fit(X_train, y_train)

model.score(X_test, y_test)

model = HistGradientBoostingClassifier()
model.fit(X_train, y_train)

model.score(X_test, y_test)

dtrain = xgb.DMatrix(X_train, label=y_train, missing=np.nan)
dtest = xgb.DMatrix(X_test, label=y_test, missing=np.nan)

param = {'objective': 'multi:softmax', 'num_class': 3}
model = xgb.train(param, dtrain, num_boost_round=100)

preds = model.predict(dtest)
accuracy = (preds == y_test).mean()
accuracy

"""На этом примере искусственно созданного пропуска мы убедились, что эти модели дейсвтительно способны работать с пропусками и для них никакой предварителной обрабокти не требуется

Есть целый набор моделей, которые сами способны обрабатывать пропуски. Для регрессии:

*   BaggingRegressor
*  DecisionTreeRegressor
*ExtraTreeRegressor
*ExtraTreesRegressor
*HistGradientBoostingRegressor
*RandomForestRegressor
*StackingRegressor
*VotingRegressor



И для классификации:



*  BaggingClassifier
*DecisionTreeClassifier
*ExtraTreeClassifier
*ExtraTreesClassifier
*HistGradientBoostingClassifier
*RandomForestClassifier
*StackingClassifier
*VotingClassifier

## 4. Сравнение методов на реальных данных

### 4.1. Air Quality Data in India

Набор данных содержит данные о качестве воздуха и AQI (индекс качества воздуха) на почасовом уровне в нескольких городах Индии.
"""

path = kagglehub.dataset_download("rohanrao/air-quality-data-in-india")
files = os.listdir(path)
dataset_file = path + '/' + files[0]

df = pd.read_csv(dataset_file,  encoding='ISO-8859-1')
df.head()

"""##### Предварительный анализ"""

df['AQI_Bucket'].unique()

"""Сперва проведем предварительный анализ.
Рассмотрим данную задачу как задачу регрессии. Поэтому в качестве таргета возьмем AQI, то есть индекс качества воздуха, а AQI_Bucket удалим, так как это категориальная оценка состояния воздуха ('Poor', 'Very Poor', 'Severe', 'Moderate', 'Satisfactory','Good').

Так же удалим город и дату, так как эти столбцы так же нам не нужны.

Останутся значения содержания различных химических элементов в воздухе и сам индекс качества AQI.

Сами химические элементы:

1. PM2.5 – Твёрдые частицы диаметром ≤ 2,5 мкм (сажа, пыль, аэрозоли).

2. PM10 – Твёрдые частицы диаметром ≤ 10 мкм (пыль, дым, пыльца).

3. NO (Оксид азота) – Газ, образующийся при горении топлива.

4. NO₂ (Диоксид азота) – Токсичный газ, продукт окисления NO.

5. NOx (Оксиды азота) – Смесь NO и NO₂, образуются при сжигании топлива.

6. NH₃ (Аммиак) – Газ с резким запахом, выделяется в сельском хозяйстве и промышленности.

7. CO (Окись углерода) – Бесцветный ядовитый газ, продукт неполного сгорания.

8. SO₂ (Диоксид серы) – Газ с резким запахом, образуется при сжигании угля и нефти.

9. O₃ (Озон) – Газ, защищающий в стратосфере, но вредный у поверхности земли.

10. Benzene (Бензол) – Летучий углеводород, канцероген, содержится в выхлопах и промышленных выбросах.

11. Toluene (Толуол) – Органическое соединение, используется в химической промышленности.

12. Xylene (Ксилол) – Ароматический углеводород, применяется в производстве красок и пластмасс.
"""

df = df.drop(columns=['City', 'Date', 'AQI_Bucket'])

df.info()

"""Всего 29530 строк, 12 признаков и 1 таргет. При этом мы видим, что в данных довольно много пропусков, что для нас нашей задачи  хорошо.

Так же отметим, что все признаки имеют числовой формат.

Посмотрим сколько всего пропусков в каждом столбце.
"""

missing_values = df.isnull().sum()
missing_values[missing_values > 0]

"""Или чуть нагляднее это можно представить в виде гистограммы:"""

filled_values = df.notnull().sum()
total_length = len(df)

plt.figure(figsize=(10, 6))
sns.barplot(x=filled_values.index, y=filled_values.values, hue=filled_values.index, palette='viridis', legend=False)

plt.axhline(y=total_length, color='black', linestyle='--', label='Общая длина датасета')

plt.title('Количество заполненных данных в каждом столбце')
plt.xlabel('Столбцы')
plt.ylabel('Количество заполненных данных')
plt.xticks(rotation=45)
plt.show()

"""Как мы видим, в данном датасете действительно довольно много пропусков. Поэтому он  нам подходит.

Посмотрим на распределение каждого признака в наших данных.
"""

num_features = df.shape[1]

plt.figure(figsize=(15, num_features * 4))

for i, column in enumerate(df.columns):
    plt.subplot(num_features, 1, i + 1)
    plt.hist(df[column], bins=80, alpha=0.7, color='blue', edgecolor='black')
    plt.title(f'Распределение для {column}')
    plt.xlabel(column)
    plt.xlim()
    plt.ylabel('Частота')

plt.tight_layout()
plt.show()

"""Как мы видим некоторые признаки имеют небольшой скос. Однако в нашем случае это не критично, так как у нас нет задачи построить хорошую модель.  Нам нужно именно проверить как обработка пропусков влияет на качество моделирования.

Так же перед началом построения моделей оценим как признаки коррелируют с таргетом с помощью матрицы корреляции:
"""

correlation_matrix = df.corr()

sns.set(style="white")
plt.figure(figsize=(16, 12))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, cbar_kws={'shrink': .8})

plt.title('Корреляционная матрица')
plt.show()

"""Как мы видим, такие переменные, как Benzene, Xylene и O3 слабо коррелируют с таргетом. Поэтому удалим их.

"""

df = df.drop(columns=['Benzene', 'Xylene', 'O3'])
df.head()

"""Теперь с этими данными приступим неприменно к  основной задаче.

Для каждого способа будем рассчитывать множество различных метрик для наглядности. А так же будем замерять время, которое ушло именно на обработку пропусков.

Обучать будем множество разных моделей, чтобы понять как обработка пропусков влияет на каждый вид модели. Рассмотрим следующие:



*   $Linear Regression$

*   $Ridge Regression$

*  $Lasso Regression$

*  $ElasticNet Regression$

*  $Random Forest$

*  $Decision Tree$

*  $Gradient Boosting$

*  $SVR$ ($Support Vector Regression$)

*  $KNN Regressor$

* $ MLP Regressor$

Для каждого спосаба обработки и каждого вида модели будем рассчитывать все метрики и время заполения пропусков и все сохранять, чтобы в даньнейшем сравнить результаты.

И так как у нас не стоит задачи получить хорошую, стабильно качественную модель, то не будем использовать кросс-валидацию и сложные конвейеры, а так же как то стараться улушчать метрики путем фича-инжинеринга или другими способами, поскольку у нас совсем другая цель работы.

##### Удаление
"""

star_time = time.time()
df_cleaned = remove_rows_with_missing_values(df)
end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_remove = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Удаление', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_remove.loc[len(result_remove)] = arr

print(f'После удаления осталось {len(df_cleaned)} строк. Когда изначально было {len(df)}.\nТо есть удалили {len(df) - len(df_cleaned)}')

"""После удаления осталось 10967 строк. Когда изначально было 29531.

То есть удалили 18564 строк.
"""

result_remove

"""Метрики получились доастаточно хорошие. Да и время работы с пропусками очень маленькой.

Однако делать какие-либо выводы рано, поскольку мы не видели результаты других методов. Поэтому повторим данную процедуру для всех способов обработки пропусков.

##### Замена константой (0)
"""

start_time = time.time()
df_cleaned = fill_missing_values_with_constant(df)
end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_constant = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Константа', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_constant.loc[len(result_constant)] = arr

result_constant

"""Так как в данном случае мы заменяли 0, то понятное дело, что MAPE посчитать не удастся, поскольку при расчете метрики в значенателе будет 0, что невозможно.

##### Замена средним значением
"""

start_time = time.time()
df_cleaned = fill_missing_values_with_mean(df)
end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_mean = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Среднее', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_mean.loc[len(result_mean)] = arr

result_mean

"""##### Замена медианой"""

start_time = time.time()
df_cleaned = fill_missing_values_with_median(df)
end_time = time.time()
total_time = end_time - start_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_median = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Медиана', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2,'Время заполнения пропусков': total_time}
    result_median.loc[len(result_median)] = arr

result_median

"""##### k ближайших соседей"""

star_time = time.time()
df_cleaned = fill_missing_values_with_knn(df)
end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_knn = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' kNN', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_knn.loc[len(result_knn)] = arr

result_knn

"""##### Метод k-Means"""

star_time = time.time()
df_cleaned = fill_missing_values_with_kmeans(df)
end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_kmeans = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' k-Means', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_kmeans.loc[len(result_kmeans)] = arr

result_kmeans

"""##### Предсказание пропуска

При попытке использования  $RandomForestRegressor()$, $DecisionTreeRegressor()$, $GradientBoostingRegressor()$ и $SVR()$ код выполнянлся более часа, после чего процесс прекратился из-за переполненного ОЗУ.
Из этого можно сделать вывод, что в данном методе нельзя использовать сложные модели, поскольку модель строится для каждого признака, где есть хотя бы 1 пропуск.

Попробуем различные модели в качестве "заполнителя" пропусков и потом выберем лучший результат.
"""

# 1.KNeighborsRegressor
star_time = time.time()

mice_imputer = IterativeImputer(estimator=KNeighborsRegressor(n_neighbors=5))
data_imputed = mice_imputer.fit_transform(df)
df_cleaned = pd.DataFrame(data_imputed, columns=df.columns)

end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_predict_knn = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Предсказание Regr', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_predict_knn.loc[len(result_predict_knn)] = arr

result_predict_knn

# 2. LinearRegression
star_time = time.time()

mice_imputer = IterativeImputer(estimator=LinearRegression())
data_imputed = mice_imputer.fit_transform(df)
df_cleaned = pd.DataFrame(data_imputed, columns=df.columns)

end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_predict_regr = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Предсказание Regr', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_predict_regr.loc[len(result_predict_regr)] = arr

result_predict_regr

# 3. Ridge
star_time = time.time()

mice_imputer = IterativeImputer(estimator=Ridge(alpha=1.0))
data_imputed = mice_imputer.fit_transform(df)
df_cleaned = pd.DataFrame(data_imputed, columns=df.columns)

end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_predict_ridge = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Предсказание Regr', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_predict_ridge.loc[len(result_predict_ridge)] = arr

result_predict_ridge

# 4. Lasso
star_time = time.time()

mice_imputer = IterativeImputer(estimator=Lasso(alpha=0.1))
data_imputed = mice_imputer.fit_transform(df)
df_cleaned = pd.DataFrame(data_imputed, columns=df.columns)

end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_predict_lasso = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Предсказание Regr', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_predict_lasso.loc[len(result_predict_lasso)] = arr

result_predict_lasso

# 5. ElasticNet
star_time = time.time()

mice_imputer = IterativeImputer(estimator=ElasticNet(alpha=0.1, l1_ratio=0.5))
data_imputed = mice_imputer.fit_transform(df)
df_cleaned = pd.DataFrame(data_imputed, columns=df.columns)

end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_predict_net = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Предсказание Regr', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_predict_net.loc[len(result_predict_net)] = arr

result_predict_net

# 6. MLPRegressor
star_time = time.time()

mice_imputer = IterativeImputer(estimator=MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))
data_imputed = mice_imputer.fit_transform(df)
df_cleaned = pd.DataFrame(data_imputed, columns=df.columns)

end_time = time.time()
total_time = end_time - star_time

X_train, X_test, y_train, y_test = train_test_split(df_cleaned.drop(columns=['AQI']), df_cleaned['AQI'], test_size=0.2, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = [
    ('Linear Regression', LinearRegression()),
    ('Ridge Regression', Ridge(alpha=1.0)),
    ('Lasso Regression', Lasso(alpha=0.1)),
    ('ElasticNet Regression', ElasticNet(alpha=0.1, l1_ratio=0.5)),
    ('Random Forest', RandomForestRegressor(random_state=42)),
    ('Decision Tree', DecisionTreeRegressor(random_state=42)),
    ('Gradient Boosting', GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)),
    ('SVR (Support Vector Regression)', SVR(kernel='rbf', C=1.0, epsilon=0.1)),
    ('KNN Regressor', KNeighborsRegressor(n_neighbors=5)),
    ('MLP Regressor', MLPRegressor(hidden_layer_sizes=(100,), max_iter=500))]

result_predict_MLPRegr = pd.DataFrame(columns=['Модель', 'MSE', 'MAE', 'MAPE', 'MedAE', 'Max Error', 'R2', 'Время заполнения пропусков'])
for name, model in models:
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    mape = mean_absolute_percentage_error(y_test, y_pred)
    medae = median_absolute_error(y_test, y_pred)
    max_err = max_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)


    arr = {'Модель': name + ' Предсказание Regr', 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'MedAE': medae, 'Max Error': max_err,'R2': r2, 'Время заполнения пропусков': total_time}
    result_predict_MLPRegr.loc[len(result_predict_MLPRegr)] = arr

result_predict_MLPRegr

"""Как ни странно, лучшие метрики получились, когда пропуски мы заполняли с помощью LinearRegression. Да и время заполения при ее использовании в качестве estimator у IterativeImputer в разы меньше, чем для более сложных моделей. Поэтому для итогового сравнения будем использовать значения, полученные именно при использовании LinearRegression в IterativeImputer.

##### Использование специальных моделей, способных обработать пропуски

Недостаток моделей, способных обрабатывать пропущенные значения, хорошо иллюстрируется на нашем примере. Если в целевой переменной $y$ y присутствуют пропуски, такие модели просто не работают.

Кроме того, обучение модели на данных с пропусками – в целом плохая практика, поскольку это существенно снижает качество прогнозирования.

Таким образом, использование подобных моделей без предварительной обработки пропущенных данных нельзя считать удачным решением.

##### Итоги

Для каждого способа заполнения пропусков мы обучивали несколько различных моделей. Однако, чтобы было легче понять, какой из методов лучше, посмотрим на графики LinearRegression (так как это самая базовая регерссионная модель) и RandomForestRegressor, GradientBoostingRegressor, MLPRegressor (так как именно эти модели получились наилучшими почти для каждого метода).

$P.S.$ Графики всех остальных моделей можно посмотреть в приложении
"""

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[0][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для LinearRegression')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[4][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для RandomForestRegressor')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[6][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для GradientBoostingRegressor')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[9][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для MLPRegressor')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

"""Для каждой модели мы рачитывали несколько различных метрик, однако в качестве основных будем использовать $MSE$, $MAE$ и $R^2$.

По графикам видно, что методы удаления и предсказания пропусков на голову лучше других способов обработки пропусков по всем метрикам.

Поэтому стоит рассматривать эти 2 варианта, как основные. При этом, удалять строки с пропусками лучше в том случае, если пропусков не сильно много и после удаления выборка останется достаточно репрезентативной.

А если же изначальный набор данных небольшой  и терять данные никак нельзя, то лучше использовать IterativeImputer. Причем преимущество данного метода заключается в том, что в качестве estimator мы можем попробовать разные модели и выбрать наилучший вариант. Недостатком же этого варианта будет то, что  использовать сложные модели будет довольно проблематично, потому что рассчет в таком случае занимает очень много времени.

Так же в пользу IterativeImputer, по сравнению с удалением, можно сказать, что далеко не факт, что модель, обученная на данных с удаленными строками, будет показывать такой же хороший результат, как и на данных, оставшихся после удаления. Ведь может быть и такое, что после удаления строк, распределение могло измениться. И в этом случае на новых данных модель уже будет работать не так хорошо.

А вот при предсказании пропусков мы сохранием виды распределений признаков, поэтому и на новых данных модель должна работать достаточно хорошо.

Так же может быть такое, что уже по обученной модели нужно предсказать значение $y$, когда известны не все $x$ (например, приборы просто не зафиксировали какой-то показатель). Тогда при использовании предсказания пропусков для построения модели мы сможем и предсказать значение $y$ даже в случае, если не все признаки известны. Этот факт так же стоит учитывать при выборе способа обрабоки пропусков.

Таким образом, можно заключить, что наилучшим способом обработки пропусков является именно предсказание пропусков. Тем более уже есть готовый метод IterativeImputer, который позволяет сделать это без лишней работы. Но если же в исходной выборке данных в избтыке и пропусков не сильно много, то можно попробовать удалить строки с пропусками и посмотреть, что получится.

## Приложение
"""

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[1][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для Ridge')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[2][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для Lasso')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[3][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для ElasticNet')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[5][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для DecisionTreeRegressor')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[7][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для SVR')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()

dataframes = [result_remove, result_constant, result_mean, result_median, result_knn, result_kmeans, result_predict_regr]

first_rows = pd.DataFrame([df.iloc[8][1:] for df in dataframes], index=[i for i in range(1, 8)])

first_rows.iloc[1, 2] = first_rows.iloc[0, 2]

fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))
axes = axes.flatten()

for i, (metric, ax) in enumerate(zip(first_rows.columns, axes)):
    if i == len(first_rows.columns) - 1:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label='Время заполнения')
    else:
        ax.plot(first_rows.index, first_rows[metric], marker='o', label=metric)
    ax.set_title(f'Диаграмма для {metric}')
    ax.set_ylabel('Значение метрики')
    ax.set_xlabel('Метод')
    ax.grid()
    ax.legend()

axes[-1].axis('off')

axes[-1].text(0.1, 0.5, '1 - Удаление\n2 - Константа\n3 - Среднее\n4 - Медиана\n5 - kNN\n6 - k_Means\n7 - Предсказание\n', ha='left', va='center', fontsize=14)

plt.suptitle('Диаграммы для KNeighborsRegressor')
plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()